{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b87b5c7-4278-4744-a278-9c304ac9e1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.27'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain import hub\n",
    "import os\n",
    "langchain.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a399ef0-72e9-4b5e-8c79-2a0042a5a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/secrets/key.secret\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ea0cfc-fdd5-4185-9460-0f9eb3b439bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000018A1523D940>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000018A1523E3C0>, root_client=<openai.OpenAI object at 0x0000018A14FFEF90>, root_async_client=<openai.AsyncOpenAI object at 0x0000018A1523E120>, model_name='gpt-4', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_chat_model(\"gpt-4\", model_provider=\"openai\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145974d7-3432-47f4-9d4a-3ae33bfe3257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour Cyril, comment puis-je vous aider aujourd'hui?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ne fonctionne pas car non chainé\n",
    "model.invoke([{\"role\": \"system\", \"content\": \"Traduis ce texte du Français à l'Italien\"}])\n",
    "response=model.invoke([{\"role\": \"user\", \"content\": \"Salut, je m'appelle Cyril\"}])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959595a1-6b80-4405-b54b-5afe10edfba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao, mi chiamo Cyril'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chainage\n",
    "system_message={\"role\": \"system\", \"content\": \"Traduis ce texte du Français à l'Italien\"}\n",
    "user_message={\"role\": \"user\", \"content\": \"Salut, je m'appelle Cyril\"}\n",
    "response=model.invoke([system_message,user_message])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d4292e-2504-428e-b34b-e842f4033007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao, mi chiamo Cyril'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Autre écriture avec une logique OO Langchain\n",
    "messages = [\n",
    "    SystemMessage(content=\"Traduis ce texte du Français à l'Italien\"),\n",
    "    HumanMessage(content=\"Salut, je m'appelle Cyril\"),\n",
    "]\n",
    "response=model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c979a02-d41f-4f2b-a35b-8e6cd5b4a4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Traduis ce texte du Francais vers {language}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template\n",
    "system_template = \"Traduis ce texte du Francais vers {language}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template),  (\"user\", \"{text}\")]\n",
    ")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bcbb95f-ac23-4b06-9dd8-429330440bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Traduis ce texte du Francais vers Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Salut, je m'appelle Cyril\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"Salut, je m'appelle Cyril\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff57524-1469-4aba-b636-9cc589ece157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao, mi chiamo Cyril.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbead9-4317-4831-903e-c535a820d97e",
   "metadata": {},
   "source": [
    "HUB RLM\n",
    "Templates préfabriqués sur le cloud\n",
    "\n",
    "rlm.rag-prompt : https://smith.langchain.com/hub/rlm/rag-prompt?_gl=1*11dcy42*_gcl_au*MTAxOTgzMzI4My4xNzYwMzQ5ODk5*_ga*MTI3MDkwMDAzMS4xNzYwMzQ5ODk5*_ga_47WX3HKKY2*czE3NjA2MzYyOTEkbzgkZzEkdDE3NjA2MzczMzkkajI0JGwwJGgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a5ab22-4053-4667-ad99-e35a5a29cc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ba589-3477-4af8-8144-a79b070a6847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le HUB RLM est une base de données de ChatPromptTemplate disponible en ligne.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"context\": \"Le Hub RLM est une base de données de ChatPromptTemplate déjà écrits et disponibles sur https://smith.langchain.com/hub/rlm/, répondre en 5 mots\", \"question\": \"Qu'est que le HUB RLM ?\"})\n",
    "response = model.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c7d3d-f31b-4e0f-9d43-ec7a82de8bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
